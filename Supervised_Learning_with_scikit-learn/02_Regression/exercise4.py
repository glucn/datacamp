# Train/test split for regression
# As you learned in Chapter 1, train and test sets are vital to ensure that your supervised learning model is able to
# generalize well to new data. This was true for classification models, and is equally true for linear regression
# models.
#
# In this exercise, you will split the Gapminder dataset into training and testing sets, and then fit and predict a
# linear regression over all features. In addition to computing the  score, you will also compute the Root Mean
# Squared Error (RMSE), which is another commonly used metric to evaluate regression models. The feature array X and
# target variable array y have been pre-loaded for you from the DataFrame df.

import numpy as np

from preload import X, y

# Import necessary modules
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# Create training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Create the regressor: reg_all
reg_all = LinearRegression()

# Fit the regressor to the training data
reg_all.fit(X_train, y_train)

# Predict on the test data: y_pred
y_pred = reg_all.predict(X_test)

# Compute and print R^2 and RMSE
print("R^2: {}".format(reg_all.score(X_test, y_test)))
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print("Root Mean Squared Error: {}".format(rmse))
